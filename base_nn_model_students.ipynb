{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Базовый модуль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data/X_Y_data/\"\n",
    "\n",
    "X = joblib.load(data_dir + \"res_X_train.pklz\")\n",
    "Y = joblib.load(data_dir + \"Y_train.pklz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиваем множество на тренировочное и тестировочное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = {}\n",
    "X_train = {}\n",
    "\n",
    "random_state = 234\n",
    "train_inds, test_inds = train_test_split(range(len(Y)), train_size=0.8, random_state=random_state)\n",
    "Y_train, Y_test = Y[train_inds], Y[test_inds]\n",
    "\n",
    "for k, v in X.items():\n",
    "    train_vals, test_vals = np.array(v)[train_inds], np.array(v)[test_inds]\n",
    "    X_train[k] = train_vals\n",
    "    X_test[k] = test_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_test_bank = joblib.load(data_dir + \"res_X_test_bank.pklz\")\n",
    "# Y_test_bank = joblib.load(data_dir + \"Y_test_bank.pklz\")\n",
    "\n",
    "# X_test_telekom = joblib.load(data_dir + \"res_X_test_telekom.pklz\")\n",
    "# Y_test_telekom = joblib.load(data_dir + \"Y_test_telekom.pklz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1_for_model(model, list_inp_params, X_test, Y_test):\n",
    "    pred = model.predict([X_test[val] for val in list_inp_params])\n",
    "    \n",
    "    pred_labels = np.argmax(pred, axis=1)\n",
    "    \n",
    "    Y_test_labels = np.argmax(Y_test, axis=1)\n",
    "    \n",
    "    f1_micro = f1_score(Y_test_labels, pred_labels, average=\"micro\", labels=[0, 2], pos_label=None)\n",
    "    f1_macro = f1_score(Y_test_labels, pred_labels, average=\"macro\", labels=[0, 2], pos_label=None)\n",
    "    \n",
    "    res = {\"f1_micro\": f1_micro, \"f1_macro\": f1_macro}\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Список признаков в X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_d2v',\n",
       " 'X_sum_ranks',\n",
       " 'X_ton_dicts',\n",
       " 'X_w2v_ruscorpora_parent',\n",
       " 'X_POS',\n",
       " 'X_w2v_web_parent',\n",
       " 'X_w2v_wikiruscorpora',\n",
       " 'X_w2v_web',\n",
       " 'X_sum_ranks_parent',\n",
       " 'X_POS_parent',\n",
       " 'X_ton_dicts_parent',\n",
       " 'X_links',\n",
       " 'X_w2v_twitter',\n",
       " 'X_inds_parent',\n",
       " 'X_w2v_wikiruscorpora_parent',\n",
       " 'X_inds',\n",
       " 'X_d2v_parent',\n",
       " 'X_w2v_twitter_parent',\n",
       " 'X_w2v_ruscorpora']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовая модель\n",
    "Редактировать только:\n",
    "```\n",
    "    ...\n",
    "    \n",
    "    ### Основная модель (редактировать только эту часть) ###\n",
    "    \n",
    "    l_D = Flatten()(l_M)\n",
    "    \n",
    "    ### Основная модель ###\n",
    "    \n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_and_evaluate_model(X_train, list_inp_params, embedding_output_dim, model_optimizer,\n",
    "                             model_loss, model_batch_size, model_nb_epoch,\n",
    "                             early_stoping_patience, model_verbose, embedding_input_dim,\n",
    "                             model_hidden_l_params):\n",
    "    # Входы модели\n",
    "    # Если вход Индекс -- то добавляем Embedding слой одинаковый для слова и родителя\n",
    "    l_inputs = [] # Входы\n",
    "    l_inp_layers = [] # Первые слои (елси нет Embedding идентичны входам)\n",
    "    embedding_all_lemms = Embedding(embedding_input_dim, embedding_output_dim, input_length=X_train[list_inp_params[0]].shape[1])\n",
    "    for val in list_inp_params:\n",
    "        if val in [\"X_inds\", \"X_inds_parent\"]:\n",
    "            model_inp = Input(shape=X_train[val].shape[1:], dtype=\"int32\")\n",
    "            model_inp_embedding = embedding_all_lemms(model_inp)\n",
    "            l_inp_layers.append(model_inp_embedding)\n",
    "        else:\n",
    "            model_inp = Input(shape=X_train[val].shape[1:])\n",
    "            l_inp_layers.append(model_inp)\n",
    "        l_inputs.append(model_inp)\n",
    "\n",
    "    # Объединяем всё\n",
    "    if len(list_inp_params) > 1:\n",
    "        l_M = merge(l_inp_layers, mode=\"concat\")\n",
    "    else:\n",
    "        # Если только 1 вход, то объединение не надо\n",
    "        l_M = l_inp_layers[0]\n",
    "\n",
    "    ### Основная модель (редактировать только эту часть) ###\n",
    "    \n",
    "    l_D = Flatten()(l_M)\n",
    "    \n",
    "    ### Основная модель ###\n",
    "    \n",
    "    # Выход\n",
    "    l_O = Dense(3, activation=\"softmax\")(l_D)\n",
    "    \n",
    "    # Компиляция модели\n",
    "    model = Model(input=l_inputs, output=[l_O])\n",
    "    model.compile(model_optimizer, model_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Обучение модели с ранним остановом\n",
    "    es = EarlyStopping(patience=early_stoping_patience)\n",
    "    h = model.fit([X_train[val] for val in list_inp_params], Y_train, batch_size=model_batch_size, nb_epoch=model_nb_epoch, callbacks=[es], verbose=model_verbose, validation_split=0.3)\n",
    "\n",
    "    # Проверка модели\n",
    "    res_f1 = f1_for_model(model, list_inp_params, X_test, Y_test)\n",
    "    return res_f1, h.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель 1\n",
    "Входные признаки:\n",
    "- word2vec по web корпусу самого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Для сохранения результатов\n",
    "l_scores = []\n",
    "model_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = \"model_1\"\n",
    "list_inp_params = [\"X_w2v_web\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель 1 Обучение и тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_micro': 0.61411549037580204, 'f1_macro': 0.52820232172093617}\n",
      "{'f1_micro': 0.61269549218031283, 'f1_macro': 0.53093866333260109}\n",
      "{'f1_micro': 0.61993627674101048, 'f1_macro': 0.53530568307177684}\n",
      "{'f1_micro': 0.61839708561020035, 'f1_macro': 0.53418278607905134}\n",
      "{'f1_micro': 0.61580630424851535, 'f1_macro': 0.53251110828712778}\n",
      "{'f1_micro': 0.61608775137111516, 'f1_macro': 0.5318645149372786}\n",
      "{'f1_micro': 0.61801385681293297, 'f1_macro': 0.53211292242093278}\n",
      "{'f1_micro': 0.61784897025171626, 'f1_macro': 0.52813085339470967}\n",
      "{'f1_micro': 0.61545538178472858, 'f1_macro': 0.53093068588784631}\n",
      "{'f1_micro': 0.62306993642143504, 'f1_macro': 0.53790398245341986}\n"
     ]
    }
   ],
   "source": [
    "# Название модели\n",
    "model_name = base_model + \"_\" + \"Model_{0}\".format(model_ind)\n",
    "model_ind += 1\n",
    "\n",
    "# Параметры модели\n",
    "embedding_output_dim = 45\n",
    "model_optimizer = \"adam\"\n",
    "model_loss = \"categorical_crossentropy\"\n",
    "model_batch_size = 100\n",
    "model_nb_epoch = 100\n",
    "early_stoping_patience = 1\n",
    "model_verbose = 0\n",
    "embedding_input_dim = X_train[\"X_inds\"].max() + 1\n",
    "\n",
    "model_hidden_l_params = {\"GRU_0\": 100,\n",
    "                         \"GRU_1\": 100,\n",
    "                         \"Dropout\": 0.2}\n",
    "\n",
    "model_params = {\"embedding_output_dim\": embedding_output_dim,\n",
    "                \"model_optimizer\": model_optimizer,\n",
    "                \"model_loss\": model_loss,\n",
    "                \"model_batch_size\": model_batch_size,\n",
    "                \"model_nb_epoch\": model_nb_epoch,\n",
    "                \"early_stoping_patience\": early_stoping_patience,\n",
    "                \"model_verbose\": model_verbose,\n",
    "                \"embedding_input_dim\": embedding_input_dim,\n",
    "                \"model_hidden_l_params\": model_hidden_l_params}\n",
    "\n",
    "for i in range(10):\n",
    "    f1, h = build_and_evaluate_model(X_train, list_inp_params, embedding_output_dim, model_optimizer,\n",
    "                                     model_loss, model_batch_size, model_nb_epoch,\n",
    "                                     early_stoping_patience, model_verbose, embedding_input_dim,\n",
    "                                     model_hidden_l_params)\n",
    "    print(f1)\n",
    "    l_scores.append((model_name, i, f1, h, model_params))\n",
    "\n",
    "# Дампим результат\n",
    "# joblib.dump(l_scores, \"res_{0}.pklz\".format(base_model), compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено\n"
     ]
    }
   ],
   "source": [
    "print(\"Выполнено\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
